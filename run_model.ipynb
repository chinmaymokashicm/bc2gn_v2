{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from func_code.process import Process\n",
    "from func_code.metrics import Metrics\n",
    "from func_code.ml import Ml\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_obj = Process()\n",
    "metrics_obj = Metrics()\n",
    "ml_obj = Ml()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps\n",
    "1. Load training and test datasets\n",
    "2. Generate feature vectors\n",
    "3. Train\n",
    "4. Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract_id</th>\n",
       "      <th>entrez_id_text</th>\n",
       "      <th>text</th>\n",
       "      <th>terms</th>\n",
       "      <th>entrez_id_term</th>\n",
       "      <th>is_acronym</th>\n",
       "      <th>common_tokens</th>\n",
       "      <th>bigram_similarity</th>\n",
       "      <th>is_small_string_substring</th>\n",
       "      <th>is_pass_filter</th>\n",
       "      <th>prefix_combined</th>\n",
       "      <th>suffix_combined</th>\n",
       "      <th>is_same_numbers</th>\n",
       "      <th>different_tokens</th>\n",
       "      <th>soft_tfidf_similarity</th>\n",
       "      <th>levenshtein_similarity</th>\n",
       "      <th>jaro_winkler_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12117771</td>\n",
       "      <td>10182</td>\n",
       "      <td>microtubule-associated serine/threonine kinase...</td>\n",
       "      <td>lipoma HMGIC fusion partner-like 4</td>\n",
       "      <td>23139</td>\n",
       "      <td>0</td>\n",
       "      <td>set()</td>\n",
       "      <td>0.129870</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>('mic', 'lip')</td>\n",
       "      <td>('kda', 'e 4')</td>\n",
       "      <td>0</td>\n",
       "      <td>{'hmgic', 'microtubule', 'fusion', 'kda', '205...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.641249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7743998</td>\n",
       "      <td>10184</td>\n",
       "      <td>ICE</td>\n",
       "      <td>KIAA0206</td>\n",
       "      <td>834</td>\n",
       "      <td>0</td>\n",
       "      <td>set()</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>('ice', 'kia')</td>\n",
       "      <td>('ice', '206')</td>\n",
       "      <td>0</td>\n",
       "      <td>{'kiaa0206', 'ice'}</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.486111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9092576</td>\n",
       "      <td>10184</td>\n",
       "      <td>interleukin-2</td>\n",
       "      <td>KIAA0206</td>\n",
       "      <td>3558</td>\n",
       "      <td>0</td>\n",
       "      <td>set()</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>('int', 'kia')</td>\n",
       "      <td>('n 2', '206')</td>\n",
       "      <td>0</td>\n",
       "      <td>{'2', 'kiaa0206', 'interleukin'}</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10910894</td>\n",
       "      <td>10184</td>\n",
       "      <td>I309</td>\n",
       "      <td>KIAA0206</td>\n",
       "      <td>6346</td>\n",
       "      <td>0</td>\n",
       "      <td>set()</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>('i30', 'kia')</td>\n",
       "      <td>('309', '206')</td>\n",
       "      <td>0</td>\n",
       "      <td>{'i309', 'kiaa0206'}</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7663511</td>\n",
       "      <td>10090</td>\n",
       "      <td>Translin</td>\n",
       "      <td>UST</td>\n",
       "      <td>7247</td>\n",
       "      <td>0</td>\n",
       "      <td>set()</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>('tra', 'ust')</td>\n",
       "      <td>('lin', 'ust')</td>\n",
       "      <td>1</td>\n",
       "      <td>{'translin', 'ust'}</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.472222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   abstract_id  entrez_id_text  \\\n",
       "0     12117771           10182   \n",
       "1      7743998           10184   \n",
       "2      9092576           10184   \n",
       "3     10910894           10184   \n",
       "4      7663511           10090   \n",
       "\n",
       "                                                text  \\\n",
       "0  microtubule-associated serine/threonine kinase...   \n",
       "1                                                ICE   \n",
       "2                                      interleukin-2   \n",
       "3                                               I309   \n",
       "4                                           Translin   \n",
       "\n",
       "                                terms  entrez_id_term  is_acronym  \\\n",
       "0  lipoma HMGIC fusion partner-like 4           23139           0   \n",
       "1                            KIAA0206             834           0   \n",
       "2                            KIAA0206            3558           0   \n",
       "3                            KIAA0206            6346           0   \n",
       "4                                 UST            7247           0   \n",
       "\n",
       "  common_tokens  bigram_similarity  is_small_string_substring  is_pass_filter  \\\n",
       "0         set()           0.129870                          0               0   \n",
       "1         set()           0.000000                          0               0   \n",
       "2         set()           0.111111                          0               0   \n",
       "3         set()           0.000000                          0               0   \n",
       "4         set()           0.000000                          0               0   \n",
       "\n",
       "  prefix_combined suffix_combined  is_same_numbers  \\\n",
       "0  ('mic', 'lip')  ('kda', 'e 4')                0   \n",
       "1  ('ice', 'kia')  ('ice', '206')                0   \n",
       "2  ('int', 'kia')  ('n 2', '206')                0   \n",
       "3  ('i30', 'kia')  ('309', '206')                0   \n",
       "4  ('tra', 'ust')  ('lin', 'ust')                1   \n",
       "\n",
       "                                    different_tokens  soft_tfidf_similarity  \\\n",
       "0  {'hmgic', 'microtubule', 'fusion', 'kda', '205...                    0.0   \n",
       "1                                {'kiaa0206', 'ice'}                    0.0   \n",
       "2                   {'2', 'kiaa0206', 'interleukin'}                    0.0   \n",
       "3                               {'i309', 'kiaa0206'}                    0.0   \n",
       "4                                {'translin', 'ust'}                    0.0   \n",
       "\n",
       "   levenshtein_similarity  jaro_winkler_similarity  \n",
       "0                0.222222                 0.641249  \n",
       "1                0.125000                 0.486111  \n",
       "2                0.000000                 0.400641  \n",
       "3                0.250000                 0.583333  \n",
       "4                0.125000                 0.472222  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"results/datasets/train.csv\")\n",
    "df = df[ml_obj.list_colnames]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract_id</th>\n",
       "      <th>entrez_id_text</th>\n",
       "      <th>text</th>\n",
       "      <th>terms</th>\n",
       "      <th>entrez_id_term</th>\n",
       "      <th>is_acronym</th>\n",
       "      <th>common_tokens</th>\n",
       "      <th>bigram_similarity</th>\n",
       "      <th>is_small_string_substring</th>\n",
       "      <th>is_pass_filter</th>\n",
       "      <th>prefix_combined</th>\n",
       "      <th>suffix_combined</th>\n",
       "      <th>is_same_numbers</th>\n",
       "      <th>different_tokens</th>\n",
       "      <th>soft_tfidf_similarity</th>\n",
       "      <th>levenshtein_similarity</th>\n",
       "      <th>jaro_winkler_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12117771</td>\n",
       "      <td>10182</td>\n",
       "      <td>microtubule-associated serine/threonine kinase...</td>\n",
       "      <td>lipoma HMGIC fusion partner-like 4</td>\n",
       "      <td>23139</td>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.129870</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(mic, lip)</td>\n",
       "      <td>(kda, e 4)</td>\n",
       "      <td>0</td>\n",
       "      <td>{hmgic, fusion, kinase, associated, microtubul...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.641249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7743998</td>\n",
       "      <td>10184</td>\n",
       "      <td>ICE</td>\n",
       "      <td>KIAA0206</td>\n",
       "      <td>834</td>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(ice, kia)</td>\n",
       "      <td>(ice, 206)</td>\n",
       "      <td>0</td>\n",
       "      <td>{kiaa0206, ice}</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.486111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9092576</td>\n",
       "      <td>10184</td>\n",
       "      <td>interleukin-2</td>\n",
       "      <td>KIAA0206</td>\n",
       "      <td>3558</td>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(int, kia)</td>\n",
       "      <td>(n 2, 206)</td>\n",
       "      <td>0</td>\n",
       "      <td>{kiaa0206, 2, interleukin}</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10910894</td>\n",
       "      <td>10184</td>\n",
       "      <td>I309</td>\n",
       "      <td>KIAA0206</td>\n",
       "      <td>6346</td>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(i30, kia)</td>\n",
       "      <td>(309, 206)</td>\n",
       "      <td>0</td>\n",
       "      <td>{kiaa0206, i309}</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7663511</td>\n",
       "      <td>10090</td>\n",
       "      <td>Translin</td>\n",
       "      <td>UST</td>\n",
       "      <td>7247</td>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(tra, ust)</td>\n",
       "      <td>(lin, ust)</td>\n",
       "      <td>1</td>\n",
       "      <td>{translin, ust}</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.472222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   abstract_id  entrez_id_text  \\\n",
       "0     12117771           10182   \n",
       "1      7743998           10184   \n",
       "2      9092576           10184   \n",
       "3     10910894           10184   \n",
       "4      7663511           10090   \n",
       "\n",
       "                                                text  \\\n",
       "0  microtubule-associated serine/threonine kinase...   \n",
       "1                                                ICE   \n",
       "2                                      interleukin-2   \n",
       "3                                               I309   \n",
       "4                                           Translin   \n",
       "\n",
       "                                terms  entrez_id_term  is_acronym  \\\n",
       "0  lipoma HMGIC fusion partner-like 4           23139           0   \n",
       "1                            KIAA0206             834           0   \n",
       "2                            KIAA0206            3558           0   \n",
       "3                            KIAA0206            6346           0   \n",
       "4                                 UST            7247           0   \n",
       "\n",
       "  common_tokens  bigram_similarity  is_small_string_substring  is_pass_filter  \\\n",
       "0            {}           0.129870                          0               0   \n",
       "1            {}           0.000000                          0               0   \n",
       "2            {}           0.111111                          0               0   \n",
       "3            {}           0.000000                          0               0   \n",
       "4            {}           0.000000                          0               0   \n",
       "\n",
       "  prefix_combined suffix_combined  is_same_numbers  \\\n",
       "0      (mic, lip)      (kda, e 4)                0   \n",
       "1      (ice, kia)      (ice, 206)                0   \n",
       "2      (int, kia)      (n 2, 206)                0   \n",
       "3      (i30, kia)      (309, 206)                0   \n",
       "4      (tra, ust)      (lin, ust)                1   \n",
       "\n",
       "                                    different_tokens  soft_tfidf_similarity  \\\n",
       "0  {hmgic, fusion, kinase, associated, microtubul...                    0.0   \n",
       "1                                    {kiaa0206, ice}                    0.0   \n",
       "2                         {kiaa0206, 2, interleukin}                    0.0   \n",
       "3                                   {kiaa0206, i309}                    0.0   \n",
       "4                                    {translin, ust}                    0.0   \n",
       "\n",
       "   levenshtein_similarity  jaro_winkler_similarity  \n",
       "0                0.222222                 0.641249  \n",
       "1                0.125000                 0.486111  \n",
       "2                0.000000                 0.400641  \n",
       "3                0.250000                 0.583333  \n",
       "4                0.125000                 0.472222  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = ml_obj.tweak_dtypes()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df[\"different_tokens\"].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mml_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_feature_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/cmokashi/bc2gn_v2/func_code/ml.py:125\u001b[0m, in \u001b[0;36mcreate_feature_matrix\u001b[0;34m(self, train_or_test, df)\u001b[0m\n\u001b[1;32m    119\u001b[0m list_row_ids \u001b[39m=\u001b[39m random\u001b[39m.\u001b[39msample(\u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, n_rows_syn_0), n_rows_syn_0_allowed)\n\u001b[1;32m    120\u001b[0m filepath \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfolderpath_dataset, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msyn_0_\u001b[39m\u001b[39m{\u001b[39;00mtrain_or_test\u001b[39m}\u001b[39;00m\u001b[39m.csv\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    121\u001b[0m list_dict_rows \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess_obj\u001b[39m.\u001b[39mread_csv_rows_by_ids(\n\u001b[1;32m    122\u001b[0m     filepath_csv\u001b[39m=\u001b[39mfilepath,\n\u001b[1;32m    123\u001b[0m     list_row_ids\u001b[39m=\u001b[39mlist_row_ids,\n\u001b[1;32m    124\u001b[0m     is_dict\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m--> 125\u001b[0m     list_colnames\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlist_colnames\n\u001b[1;32m    126\u001b[0m )\n\u001b[1;32m    127\u001b[0m \u001b[39m# list_dict_rows = [{key: value for key, value in dict_row if key != \"index\"} for dict_row in list_dict_rows]\u001b[39;00m\n\u001b[1;32m    128\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(list_dict_rows)\n",
      "File \u001b[0;32m~/miniconda3/envs/bc2gn/lib/python3.10/site-packages/pandas/core/series.py:4771\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4661\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[1;32m   4662\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   4663\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4666\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   4667\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[1;32m   4668\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4669\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4670\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4769\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4770\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4771\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[0;32m~/miniconda3/envs/bc2gn/lib/python3.10/site-packages/pandas/core/apply.py:1123\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[1;32m   1122\u001b[0m \u001b[39m# self.f is Callable\u001b[39;00m\n\u001b[0;32m-> 1123\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[0;32m~/miniconda3/envs/bc2gn/lib/python3.10/site-packages/pandas/core/apply.py:1174\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1172\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1173\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[0;32m-> 1174\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[1;32m   1175\u001b[0m             values,\n\u001b[1;32m   1176\u001b[0m             f,\n\u001b[1;32m   1177\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[1;32m   1178\u001b[0m         )\n\u001b[1;32m   1180\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1181\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1182\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1183\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/miniconda3/envs/bc2gn/lib/python3.10/site-packages/pandas/_libs/lib.pyx:2924\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/data/cmokashi/bc2gn_v2/func_code/ml.py:73\u001b[0m, in \u001b[0;36mgenerate_features\u001b[0;34m(self, list_text)\u001b[0m\n\u001b[1;32m     71\u001b[0m                 dict_n_rows[is_syn] \u001b[39m=\u001b[39m {}\n\u001b[1;32m     72\u001b[0m             dict_n_rows[is_syn][filename\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m_\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m2\u001b[39m]\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m0\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(\u001b[39m1\u001b[39m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m f)\n\u001b[0;32m---> 73\u001b[0m \u001b[39mreturn\u001b[39;00m dict_n_rows\n",
      "File \u001b[0;32m~/miniconda3/envs/bc2gn/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/bc2gn/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:1019\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1010\u001b[0m head_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_head_mask(head_mask, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m   1012\u001b[0m embedding_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(\n\u001b[1;32m   1013\u001b[0m     input_ids\u001b[39m=\u001b[39minput_ids,\n\u001b[1;32m   1014\u001b[0m     position_ids\u001b[39m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1017\u001b[0m     past_key_values_length\u001b[39m=\u001b[39mpast_key_values_length,\n\u001b[1;32m   1018\u001b[0m )\n\u001b[0;32m-> 1019\u001b[0m encoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(\n\u001b[1;32m   1020\u001b[0m     embedding_output,\n\u001b[1;32m   1021\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[1;32m   1022\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m   1023\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m   1024\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_extended_attention_mask,\n\u001b[1;32m   1025\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[1;32m   1026\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m   1027\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1028\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m   1029\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m   1030\u001b[0m )\n\u001b[1;32m   1031\u001b[0m sequence_output \u001b[39m=\u001b[39m encoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1032\u001b[0m pooled_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler(sequence_output) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpooler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/bc2gn/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/bc2gn/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:609\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    600\u001b[0m     layer_outputs \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mcheckpoint\u001b[39m.\u001b[39mcheckpoint(\n\u001b[1;32m    601\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m    602\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    606\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    607\u001b[0m     )\n\u001b[1;32m    608\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 609\u001b[0m     layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[1;32m    610\u001b[0m         hidden_states,\n\u001b[1;32m    611\u001b[0m         attention_mask,\n\u001b[1;32m    612\u001b[0m         layer_head_mask,\n\u001b[1;32m    613\u001b[0m         encoder_hidden_states,\n\u001b[1;32m    614\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    615\u001b[0m         past_key_value,\n\u001b[1;32m    616\u001b[0m         output_attentions,\n\u001b[1;32m    617\u001b[0m     )\n\u001b[1;32m    619\u001b[0m hidden_states \u001b[39m=\u001b[39m layer_outputs[\u001b[39m0\u001b[39m]\n\u001b[1;32m    620\u001b[0m \u001b[39mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/miniconda3/envs/bc2gn/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/bc2gn/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:537\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    534\u001b[0m     cross_attn_present_key_value \u001b[39m=\u001b[39m cross_attention_outputs[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m    535\u001b[0m     present_key_value \u001b[39m=\u001b[39m present_key_value \u001b[39m+\u001b[39m cross_attn_present_key_value\n\u001b[0;32m--> 537\u001b[0m layer_output \u001b[39m=\u001b[39m apply_chunking_to_forward(\n\u001b[1;32m    538\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeed_forward_chunk, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mchunk_size_feed_forward, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mseq_len_dim, attention_output\n\u001b[1;32m    539\u001b[0m )\n\u001b[1;32m    540\u001b[0m outputs \u001b[39m=\u001b[39m (layer_output,) \u001b[39m+\u001b[39m outputs\n\u001b[1;32m    542\u001b[0m \u001b[39m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/bc2gn/lib/python3.10/site-packages/transformers/pytorch_utils.py:249\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[39m# concatenate output at same dimension\u001b[39;00m\n\u001b[1;32m    247\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mcat(output_chunks, dim\u001b[39m=\u001b[39mchunk_dim)\n\u001b[0;32m--> 249\u001b[0m \u001b[39mreturn\u001b[39;00m forward_fn(\u001b[39m*\u001b[39;49minput_tensors)\n",
      "File \u001b[0;32m~/miniconda3/envs/bc2gn/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:550\u001b[0m, in \u001b[0;36mBertLayer.feed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfeed_forward_chunk\u001b[39m(\u001b[39mself\u001b[39m, attention_output):\n\u001b[1;32m    549\u001b[0m     intermediate_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintermediate(attention_output)\n\u001b[0;32m--> 550\u001b[0m     layer_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moutput(intermediate_output, attention_output)\n\u001b[1;32m    551\u001b[0m     \u001b[39mreturn\u001b[39;00m layer_output\n",
      "File \u001b[0;32m~/miniconda3/envs/bc2gn/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/bc2gn/lib/python3.10/site-packages/transformers/models/bert/modeling_bert.py:464\u001b[0m, in \u001b[0;36mBertOutput.forward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    462\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdense(hidden_states)\n\u001b[1;32m    463\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(hidden_states)\n\u001b[0;32m--> 464\u001b[0m hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mLayerNorm(hidden_states \u001b[39m+\u001b[39;49m input_tensor)\n\u001b[1;32m    465\u001b[0m \u001b[39mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[0;32m~/miniconda3/envs/bc2gn/lib/python3.10/site-packages/torch/nn/modules/module.py:1188\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1185\u001b[0m             tracing_state\u001b[39m.\u001b[39mpop_scope()\n\u001b[1;32m   1186\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n\u001b[0;32m-> 1188\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call_impl\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   1189\u001b[0m     forward_call \u001b[39m=\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slow_forward \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_get_tracing_state() \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward)\n\u001b[1;32m   1190\u001b[0m     \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m     \u001b[39m# this function, and just call forward.\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ml_obj.create_feature_matrix(df=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 ('bc2gn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0504ac3e76d7ef4ae22541ac1d13e3fb765c41cf2cc7fa5f55a4d27c5ae99cc0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
